{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten extraction\n",
    "The answer sheet pdf or image will be uploaded to the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "GOOGLE_API_KEY = \"AIzaSyCr04_iyPZP6Dx2dB5JpUAqd3A1sJa9U0A\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textExtraction(img):\n",
    "    if type(img) == str:\n",
    "        if img.endswith(\".pdf\"):\n",
    "            img = convert_from_path(img, dpi=300)\n",
    "        else:\n",
    "            img = Image.open(img)\n",
    "    sysPrompt = \"You are a handwritten text recognition expert. You will be given images of handwritten text. Your job is provide an exact trascription of the text in the image/document and separate the answers using a delimeter. All the answers should be separated using this special character '%&$'.\"\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro-latest', system_instruction=sysPrompt)\n",
    "    res = model.generate_content(img).text\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textSort(txt):\n",
    "    sysPrompt = \"\"\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro-latest', system_instruction=sysPrompt)\n",
    "    res = model.generate_content([txt, \"Separate these answers\"]).text\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diagram illustrates the various applications and benefits of a smart home system, centering around a house icon. \n",
      "\n",
      "**Core Functions:**\n",
      "\n",
      "* **Automatic operation of appliances:** This overarching function is enabled by various smart devices and sensors within the house.\n",
      "* **Security:** Represented in two ways:\n",
      "    *  As a standalone benefit, suggesting overall home protection.\n",
      "    *  Linked to \"Security Cameras\", indicating remote monitoring capabilities.\n",
      "* **Energy conservation:** Highlighting the system's role in efficient energy management. \n",
      "* **Hassle-free lifestyle:**  This benefit is connected to several smart home features that simplify daily routines.\n",
      "* **Entertainment:** Signifying the integration of entertainment devices and systems.\n",
      "\n",
      "**Supporting Features:**\n",
      "\n",
      "These features are categorized based on their primary function within the smart home ecosystem:\n",
      "\n",
      "* **Security:**\n",
      "    * Security cameras\n",
      "    * Smart locks \n",
      "* **Energy Conservation:**\n",
      "    * Smart Thermostat\n",
      "    * Smart meters\n",
      "* **Hassle-free lifestyle:**\n",
      "    * Smart TV\n",
      "    * Smart irrigation\n",
      "    * Remote monitoring\n",
      "* **Other:**\n",
      "    * Communication with a smart grid\n",
      "    * Gas sensors \n",
      "    * Smoke sensors \n",
      "\n",
      "**Health Care:**\n",
      "\n",
      "*  While not directly linked to specific devices, \"Health Care\" is positioned within the outer ring, implying potential future integration or benefits of a smart home system in this area. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = genai.GenerativeModel('gemini-1.5-pro-latest', system_instruction=\"You are an evaluator's assistant tasked with extracting information out of diagramatic answers.\")\n",
    "df = \"STApp/Images/2.jpg\"\n",
    "imf = Image.open(df)\n",
    "print(mod.generate_content(imf).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's diagram accurately captures the core elements and relationships of data structures, mirroring the answer key's structure. \n",
      "\n",
      "**Similarities:**\n",
      "\n",
      "* **Main Categories:** Both diagrams successfully differentiate between \"Primitive Data Structures\" and \"Non-Primitive Data Structures.\"\n",
      "* **Primitive Subtypes:**  They both correctly list Integer, Character, and Boolean. The student uses \"Real\" while the answer key opts for the more programming-centric \"Float,\" both conveying the same meaning in this context.\n",
      "* **Non-Primitive Breakdown:** Both accurately divide \"Non-Primitive Data Structures\" into \"Linear\" and \"Nonlinear.\"  Key examples like Arrays, Linked Lists, Trees, and Graphs are present in both.\n",
      "\n",
      "**Differences & Potential Enhancements:**\n",
      "\n",
      "* **Terminology:**  The answer key uses \"Nonprimitive\" while the student uses \"Non-Primitive.\" While not incorrect, adopting consistent, industry-standard terms enhances clarity.\n",
      "* **Completeness:** The answer key includes \"Hash Table\" under \"Nonlinear Data Structures,\" which the student omits. This addition would make the student's diagram more comprehensive.\n",
      "* **Visual Presentation:** The answer key's use of color and modern styling enhances readability and visual appeal. This is not a criticism of the student's diagram, but rather an observation on the impact of presentation. \n",
      "\n",
      "**Overall:** The student demonstrates a solid understanding of data structures fundamentals. Incorporating the minor additions and refinements mentioned above would elevate their diagram to be even more aligned with the answer key and reflect a deeper grasp of the topic. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = genai.GenerativeModel('gemini-1.5-pro-latest', system_instruction=\"You are an evaluator's assistant tasked with evaluating if the student's diagram matches the answerkey's diagram an finding if the essence and meaning of he diagram same. You will be given he student's image followed by the correct image\")\n",
    "aa = \"STApp/Images/b.jpg\"\n",
    "bb = \"STApp/Images/a.png\"\n",
    "imf = Image.open(aa)\n",
    "ims = Image.open(bb)\n",
    "print(mod.generate_content([imf,ims]).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is no text in this image. %&$ \\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = textExtraction(\"STApp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.) BERT model:- \n",
      "Bert is designed to generate a language model . so,only the encoder mechanism in used. sequence of tokens are fed to the transformer model . These tokens are first embedded into vectors and then processed in the neural network . \n",
      "The output sequence of vectors , each corresponding to an input token , Providing contextualized representations. \n",
      "\n",
      "Masked Language model : \n",
      "Masking Words : BERT hides about 15% of words in a sentence with a speau token. \n",
      "Guessing Hidden words : BERT guess the masked words by analyzing the context of neighboring words.\n",
      "Learning Process : Uses a speacial layer to guess and convert these guesses into probabilities. \n",
      "\n",
      "Focus on Masked Words : BERT emphasizes predicting masked words to enhance understanding of context and meaning.\n",
      "\n",
      "Next Sentence Prediction (NSP) : \n",
      "Sentence Pair Relationship : Trains BERT to understand if two sentences are sequential in a document .\n",
      "Balanced Training Pairs : 50% pairs are consecutive 50% are random sentences. \n",
      "Input Processing : Add special tokens, sentence embeddings and positional embeddings to prepare data to do NSP. \n",
      "Prediction Mechanism : Uses the output of CLS token to determine sentence connection probabilities through a classification layer and SoftMax. \n"
     ]
    }
   ],
   "source": [
    "print(result.split(\"%&$\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the answers into a list of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q) Tiny ML : \n",
      "Tiny ML refers to the field of machine learning that focuses on developing models and algorithms optimized for resource - constrained devices, such as micro controllers and edge devices. \n",
      "\n",
      "Key characteristics : \n",
      "Resource Efficiency : Tiny ML model are optimized to use minimal computational resources, enabling them to run efficiently on devices with limited CPU power and memory through methods like quantization -pruning and architecture optimization.\n",
      "Low Power Consumption : Tiny ML aims to enable machine learning on devices with low power requirements , allowing them to operate for long periods without frequent recharging, which is essential for wearable devices, remote access sensors, etc.\n",
      "\n",
      "APPLICATIONS : \n",
      "Health care applications : Tiny ML is used in wearable health monitors to track vital signs continuously, detect irregularities, and provide early warnings, enhancing personalized medicine and remote patient monitoring.\n",
      "Agriculture Applications : In precision agriculture, Tiny ML - powered sensors monitor soil moisture, temperature, and crop health, optimizing resource use and increasing yields.\n",
      "Industrial IoT Applications : Tiny ML facilitates predictive maintenance and condition monitoring in manufacturing by analyzing real - time sensor data to predict equipment failures and reduce downtime.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_into_list(text):\n",
    "    pattern = r\"(?i)\\b[qa]\\d+\\s*[\\).]?\\b|[a-h]\\s*\\)|\\b(?:Q|Question|A|Answer|Ans|Ques)?\\s*?(\\d+)\\s*[)]?\"\n",
    "    questions = re.split(pattern, text)\n",
    "    pq = []\n",
    "    for i in range(1, len(questions)-1, 2):\n",
    "        #question_number = \"Q\" + str(questions[i]) + \")\"\n",
    "        question_text = questions[i+1].strip()\n",
    "        pq.append(question_text)\n",
    "    return pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\") Reactive Agents: \\nReactive agents are driven by the principle of responding to changes in their environment. They operate on a stimulus-response basis, where they continuously monitor their environment and take actions directly in response to perceived stimuli.\\nEg:\\nA robot vacuum cleaner that moves around a room, changing direction when it encounters an obstacle. It does not plan its route or remember where it has been, it simply reacts to obstacles in its path. \\nProactive Agents:\\nProactive agents are capable of anticipating future states of the environment and taking actions that move them towards achieving their objectives. \\nEg:\\nA chess playing program that anticipates the opponent's moves and plans several steps ahead. \\n\\n\\nto achieve the goal of winning the game.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resde = \"\"\"Q1) Reactive Agents: \n",
    "Reactive agents are driven by the principle of responding to changes in their environment. They operate on a stimulus-response basis, where they continuously monitor their environment and take actions directly in response to perceived stimuli.\n",
    "Eg:\n",
    "A robot vacuum cleaner that moves around a room, changing direction when it encounters an obstacle. It does not plan its route or remember where it has been, it simply reacts to obstacles in its path. \n",
    "Proactive Agents:\n",
    "Proactive agents are capable of anticipating future states of the environment and taking actions that move them towards achieving their objectives. \n",
    "Eg:\n",
    "A chess playing program that anticipates the opponent's moves and plans several steps ahead. \n",
    "\n",
    "\n",
    "to achieve the goal of winning the game. \n",
    "a2) Organization as an Agent:\n",
    "This perspective sees an organization as a unified entity that makes strategic decisions, plans and take actions to achieve specific goals similar to an intelligent agent in a multi agent system. For example, a multinational corporation acts as a single entity in decision-making, negotiations, and competition to maximize profits and achieve long-term objectives.\n",
    "Organization as an Institutions:\n",
    "This perspective focuses on the organization as a structure composed of rules, norms and roles that guide the behavior of its members. It emphasizes the framework that shapes behaviors within the organization, such as a university that operates based on academic rules etc. \n",
    "\n",
    "\n",
    "Q3) Accessible Environment: \n",
    "Agents does not have full access to all the information about the state of the environment\n",
    "Inaccessible Environment:\n",
    "These have complete and accurate information about the state of the environment at any given time.\n",
    "Deterministic Environment :\n",
    "In this environment actions may have uncertain or probabilistic outcomes.\n",
    "Non- deterministic Environment :\n",
    "In this environment agents actions is predictable and consistent.\n",
    "Q4) Belief- desire- Intention :\n",
    "Belief represents the information that an agent has about the world , including its environment , other agents and itself.\n",
    "Desire represents the goals or objectives that the agent wants to achieve. These are the \n",
    "\n",
    "\n",
    "outcomes or states of the world that the agents finds desirable.\n",
    "Intentions are the plans or commitments that an agent decides to pursue in order to achieve it desires. Intentions represent the chosen course of action that the agent is committed to executing.\n",
    "sensor input --> belief revision --> beliefs --> generate options --> desires --> filter --> Intentions --> action output\n",
    "\"\"\"\n",
    "\n",
    "split_into_list(resde)[0].lstrip(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer key recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                   INTERNET OF THINGS  - ANSWER KEY  \\nQuestion 1:  \\nWhat is active sensor and passive sensor?  \\nAnsw er 1: \\nActive Sensors  \\nThese generate energy to scan the things and locations and then a sensor \\nidentifies and calculates the amount of either backscattered or reflected \\nradiation from the target object. The examples of active sensors are \\nRADAR and LIDAR where the time difference that is in between the \\nemission process and return process is calculated by determining the area, \\nspeed, and object direction.  \\nPassive Sensors  \\nThese sensors collect radiation which is either radiated or reflected by the \\nsurrounding locations or object. The most crucial example of a passive \\nsensor is reflected sunlight. And the other examples are radiometers, \\ncharge -coupled objects, infrared, and film camera work.  \\nQuestion 2:  \\nWhat is analog sensor and digital sensor?  \\nAnswer 2:  \\nAnalog Sensors  \\nThere are different types of sensors that produce continuous analog output \\nsignal and these sensors are considered as analog sensors. This continuous \\noutput signal produced by the analog sensors is proportional to the \\nmeasurand. There are various types of analog sensors; practical examples \\nof various types of analog sensors are as follows: accelerometers, pressure \\nsensors, light sensors, sound sensors, temperature sensors, and so on.  \\nDigital Sensors  \\nElectronic sensors or electrochemical sensors in which data conversion \\nand data transmission takes place digitally are called as digital sensors. \\nThese digital sensors are replacing analog sensors as they are capable of \\novercoming the drawbacks of analog s ensors.   '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        \n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "\n",
    "    \n",
    "    qa_dict = {}\n",
    "    \n",
    "    question_pattern = re.compile(r'(Q\\s*\\d+|Ques\\s*\\d+|Question\\s*\\d+):', re.IGNORECASE)\n",
    "    answer_pattern = re.compile(r'(Ans\\s*\\d+|Answer\\s*\\d+|Answ er\\s*\\d+):', re.IGNORECASE)\n",
    "    \n",
    "    questions = re.split(question_pattern, text)\n",
    "    \n",
    "    for i in range(1, len(questions), 2):\n",
    "        question_number = questions[i].strip()\n",
    "        question_text = questions[i + 1].strip()\n",
    "        \n",
    "        answer_match = answer_pattern.search(question_text)\n",
    "        if answer_match:\n",
    "            answer_start = answer_match.start()\n",
    "            answer_number = answer_match.group()\n",
    "            \n",
    "            question_only = question_text[:answer_start].strip().replace('\\n', ' ')\n",
    "            answer_only = question_text[answer_start + len(answer_number):].strip().replace('\\n', ' ')\n",
    "            qa_dict[question_only] = answer_only\n",
    "    \n",
    "    return qa_dict\n",
    "\n",
    "er,tx = extract_text_from_pdf(\"Answer key.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Answer key christ format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ii)Analyze the hardware setup used for this purpose. (4 marks)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def enhanced_extract_questions_from_pdf(pdf_path):\n",
    "    questions = []\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        full_text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            full_text += page.extract_text() + \"\\n\"\n",
    "        \n",
    "        lines = full_text.split('\\n')\n",
    "        \n",
    "        question_detected = False\n",
    "        question_text = \"\"\n",
    "        for line in lines:\n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line.startswith(('Q.', 'i)', 'ii)', 'iii)', 'a)', 'b)')):\n",
    "                if question_detected:\n",
    "                    questions.append(question_text.strip())\n",
    "                question_text = stripped_line\n",
    "                question_detected = True\n",
    "            elif question_detected:\n",
    "                question_text += \" \" + stripped_line\n",
    "        \n",
    "        if question_detected:\n",
    "            questions.append(question_text.strip())\n",
    "    \n",
    "    return questions\n",
    "\n",
    "questions = enhanced_extract_questions_from_pdf('doc2.pdf')\n",
    "\n",
    "questions[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDiag(ans):\n",
    "    sysPrompt = \"You are tasked to determine whether a given student's answer has any kind of diagrams or not. A diagram can be anything between a simple flowchart to a complex labelled diagram of a human heart.\"\n",
    "    prmpt = \"Does this image of a student's anwerscript have any kind of diagram in it. Just reply with a yes if it has a diagram and a no if it doesnt\"\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro-latest', system_instruction=sysPrompt)\n",
    "    res = model.generate_content([ans,prmpt]).text\n",
    "    if 'yes' in res.lower().strip():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"The image contains a diagram. It appears to be an Entity-Relationship Diagram (ERD), which is a type of diagram used in database design. \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 301,\n",
       "        \"candidates_token_count\": 29,\n",
       "        \"total_token_count\": 330\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"df.jpeg\")\n",
    "checkDiag(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGENT 1 - Keywords and semantic matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evalkey(ques,key,ans):\n",
    "    grades = {}\n",
    "    suggestions = {}\n",
    "    sysPrompt = \"You are an external evaluator. You are tasked with evaluating the answers of student using only an answer key. The answer key will contain certain keywords, which you have to match in the stuents answer. If all the keywords in the answer key matches the student answer with correct semantic and contextual representation, the student should be awarded high score. Evaluation is out of 10. Your input will be quesitons, followed by the answer keys and finally followed by the student answers.\"\n",
    "    model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=sysPrompt)\n",
    "    prmt = \"Your output should be in the format: <score><SEP><suggestions>\"\n",
    "    \n",
    "\n",
    "    for p,(i,j,k) in enumerate(zip(ques,key,ans)):\n",
    "        resil = model.generate_content([i,j,k,prmt]).text\n",
    "        spl = resil.split(\"<SEP>\")\n",
    "        score = int(spl[0])\n",
    "        sugg = str(spl[1])\n",
    "        grades[i] = score\n",
    "        suggestions[i] = sugg\n",
    "    return grades, suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'er' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mer\u001b[49m\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m      2\u001b[0m ques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(er\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      3\u001b[0m ans \u001b[38;5;241m=\u001b[39m split\n",
      "\u001b[0;31mNameError\u001b[0m: name 'er' is not defined"
     ]
    }
   ],
   "source": [
    "key = list(er.values())\n",
    "ques = list(er.keys())\n",
    "ans = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mkey\u001b[49m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,ques,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,ans)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'key' is not defined"
     ]
    }
   ],
   "source": [
    "print(key,\"\\n\",ques,\"\\n\",ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0, 1: 0},\n",
       " {'What is active sensor and passive sensor?': 'The student has completely misunderstood the concepts of active and passive sensors. They have reversed the definitions and provided incorrect examples.  The student needs to review the definitions of active and passive sensors and focus on how they interact with the environment. \\n',\n",
       "  'What is analog sensor and digital sensor?': 'The student has confused the definitions of analog and digital sensors. They need to review the concepts of continuous vs. discrete signals and the examples given are incorrect. \\n'})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evalkey(ques,key,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = {}\n",
    "suggestions = {}\n",
    "for p,(i,j,k) in enumerate(zip(ques,key,ans)):\n",
    "    resil = Evalkey(i,j,k)\n",
    "    spl = resil.split(\"<SEP>\")\n",
    "    score = int(spl[0])\n",
    "    sugg = str(spl[1])\n",
    "    grades[p] = score\n",
    "    suggestions[i] = sugg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'What is active sensor and passive sensor?': 'The student has a significant misunderstanding of active and passive sensors. They have reversed the definitions, claiming that active sensors rely on ambient environment and passive sensors emit their own energy. The examples provided are also incorrect. The student needs to review the concepts and definitions of active and passive sensors. \\n',\n",
       " 'What is analog sensor and digital sensor?': 'The student has misunderstood the definitions of analog and digital sensors. They need to review the concepts and understand the difference between continuous and discrete signals. The examples they provided are also incorrect, as a digital thermometer is a digital sensor, and a mercury thermometer is an analog sensor. \\n'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'What is active sensor and passive sensor?': \"The student has completely misunderstood the concepts of active and passive sensors. Their answer is entirely opposite to the definitions provided in the answer key. \\n\\n* **Active sensors** should be defined as devices that emit their own energy to probe the environment.  \\n* **Passive sensors** should be defined as devices that detect energy emitted or reflected by the environment. \\n\\nThe student's examples are also incorrect. A standard thermometer is a passive sensor (it measures the heat emitted by an object), and a laser pointer is an active sensor (it emits its own light). \\n\",\n",
       " 'What is analog sensor and digital sensor?': 'The student has a fundamental misunderstanding of analog and digital sensors. The definitions are completely reversed, and the examples provided are incorrect. The student should review the definitions and examples of analog and digital sensors. \\n'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printgrades\n",
    "suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q1) Active sensors :- \\nActive sensors do not generate any energy on their own. Instead, they rely entirely on the ambient environment to function. Some of the examples are standard thermometer etc. \\n\\nPassive sensors :-\\nPassive sensors are those that actively emit their own energy to scan and detect objects or surroundings. Laser pointer is an example of the passive sensor.',\n",
       " 'Q2) Analog sensors :- \\nAnalog sensors produce discrete, digital signals rather than continuous outputs. Digital thermometer is an example of analog sensors.\\n\\nDigital sensors :- \\nDigital sensors generate continuous wave signals and do not convert data into binary or any other digital format. Old fashioned mercury thermometer is an example for digital sensor.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_ans(ans):\n",
    "    return [re.sub(r'Q\\d+\\)\\s*|\\n+', ' ', x).strip() for x in ans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is active sensor and passive sensor?',\n",
       " 'What is analog sensor and digital sensor?']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(er.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGENT 2 - Internet researcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evalref(ques,ans,subject):\n",
    "    sysPrompt = f\"Your are an expert in the subject of {subject}. You come from a long practicing background of experienced subject expert in your field.\\\n",
    "          You are tasked to evaluate a set of questions and their respective answers given by students. The input to you will be a question followed by its respective student answer. \\\n",
    "            Your task is to use your subject knowledege and evaluate the answers out of a total of 10 marks.\"\n",
    "    model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=sysPrompt)\n",
    "    prmt = \"Your output should be in **plain text** and in the format: <score><SEP><suggestions>. Here score is just a number like 5 and suggestions are in plain textz\"\n",
    "    grades = {}\n",
    "    suggestions = {}\n",
    "\n",
    "    for p,(i,j) in enumerate(zip(ques,ans)):\n",
    "        resil = model.generate_content([i,j,prmt]).text\n",
    "        spl = resil.split(\"<SEP>\")\n",
    "        score = int(spl[0])\n",
    "        sugg = str(spl[1])\n",
    "        grades[i] = score\n",
    "        suggestions[i] = sugg\n",
    "    return grades, suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Evalref' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mEvalref\u001b[49m(ques,ans,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInternet of things\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Evalref' is not defined"
     ]
    }
   ],
   "source": [
    "Evalref(ques,ans,\"Internet of things\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGENT 3 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q2) Analog sensors :- \\nAnalog sensors produce discrete, digital signals rather than continuous outputs. Digital thermometer is an example of analog sensors.\\n\\nDigital sensors'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strre = \"Q2) Analog sensors :- \\nAnalog sensors produce discrete, digital signals rather than continuous outputs. Digital thermometer is an example of analog sensors.\\n\\nDigital sensors\"\n",
    "strre.strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAI471', 'MAI431', 'MAI432']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COURSE = {\n",
    "    'MAI471':\"Large Language Models\",\n",
    "    'MAI431':\"Internet of Things\",\n",
    "    'MAI432':\"Multi Agent Systems\"\n",
    "}\n",
    "\n",
    "list(COURSE.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sq\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sq.connect('STApp/utils/app.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_answerscript(transcript):\n",
    "    pattern = r'(?:Answer\\s*\\d+:|Q\\d+:|\\d+\\.\\s|A\\d*\\)|Q\\d*\\)|A\\.|Q\\.|a\\)|A\\s|Q\\s|a\\s|Ans\\.|Ans|Ans\\d*\\)|ans\\d*\\)|ques\\s*\\d*\\)|Ques\\d*\\)|q\\d*\\))'\n",
    "    \n",
    "\n",
    "    # Use re.split() to split the transcript by the pattern\n",
    "    answers = re.split(pattern, transcript)\n",
    "\n",
    "    # Remove any empty strings resulting from splitting and strip any leading/trailing whitespace\n",
    "    answers = [answer.strip() for answer in answers if answer.strip()]\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reactive Agents: \\nReactive agents are driven by the principle of responding to changes in their environment. They operate on',\n",
       " 'stimulus-response basis, where they continuously monitor their environment and take actions directly in response to perceived stimuli.\\nEg:',\n",
       " 'robot vacuum cleaner that moves around',\n",
       " 'room, changing direction when it encounters an obstacle. It does not plan its route or remember where it has been, it simply reacts to obstacles in its path. \\nProactive Agents:\\nProactive agents are capable of anticipating future states of the environment and taking actions that move them towards achieving their objectives. \\nEg:',\n",
       " \"chess playing program that anticipates the opponent's moves and plans several steps ahead. \\n\\n\\nto achieve the goal of winning the game. \\na2) Organization as an Agent:\\nThis perspective sees an organization as\",\n",
       " 'unified entity that makes strategic decisions, plans and take actions to achieve specific goals similar to an intelligent agent in',\n",
       " 'multi agent system. For example,',\n",
       " 'multinational corporation acts as',\n",
       " 'single entity in decision-making, negotiations, and competition to maximize profits and achieve long-term objectives.\\nOrganization as an Institutions:\\nThis perspective focuses on the organization as',\n",
       " 'structure composed of rules, norms and roles that guide the behavior of its members. It emphasizes the framework that shapes behaviors within the organization, such as',\n",
       " 'university that operates based on academic rules etc.',\n",
       " 'Accessible Environment: \\nAgents does not have full access to all the information about the state of the environment\\nInaccessible Environment:\\nThese have complete and accurate information about the state of the environment at any given time.\\nDeterministic Environment :\\nIn this environment actions may have uncertain or probabilistic outcomes.\\nNon- deterministic Environment :\\nIn this environment agents actions is predictable and consistent.',\n",
       " 'Belief- desire- Intention :\\nBelief represents the information that an agent has about the world , including its environment , other agents and itself.\\nDesire represents the goals or objectives that the agent wants to achieve. These are the \\n\\n\\noutcomes or states of the world that the agents finds desirable.\\nIntentions are the plans or commitments that an agent decides to pursue in order to achieve it desires. Intentions represent the chosen course of action that the agent is committed to executing.\\nsensor input --> belief revision --> beliefs --> generate options --> desires --> filter --> Intentions --> action output']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_answerscript(resde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>evaluator_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>questions</th>\n",
       "      <th>score</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MAI471</td>\n",
       "      <td>Q1)\\nArchitecture of LLM:-\\nInput embeddings :...</td>\n",
       "      <td>Explain the architecture of llm.,Describe the ...</td>\n",
       "      <td>15.5</td>\n",
       "      <td>**FINAL REPORT**\\n\\n**INTERNAL REPORT**\\n\\nQ1:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   report_id  student_id  evaluator_id course_id  \\\n",
       "0          1           1             1    MAI471   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  Q1)\\nArchitecture of LLM:-\\nInput embeddings :...   \n",
       "\n",
       "                                           questions  score  \\\n",
       "0  Explain the architecture of llm.,Describe the ...   15.5   \n",
       "\n",
       "                                              report  \n",
       "0  **FINAL REPORT**\\n\\n**INTERNAL REPORT**\\n\\nQ1:...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = pd.read_sql_query('SELECT * FROM report_details', con)\n",
    "ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split(transcript):\n",
    "\n",
    "\n",
    "    pattern = r'(Q\\d+\\)|q\\d+\\)|A\\d+\\)|a\\d+\\)|A\\)|a\\)|\\d+\\)|\\(\\d+\\)|\\d+\\.\\))'\n",
    "    \n",
    "    answers = re.split(pattern, transcript)\n",
    "\n",
    "    answers = [answers[i] + answers[i + 1] for i in range(1, len(answers), 2)]\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(2) BERT model :-\\nBert is designed to generate a language model so, only the encoder mechanism is used . Sequence of tokens are fed to the transformer model . These tokens are first embedded into vectors and then processed in the neural network . \\nThe output is a sequence of vectors, each corresponding to an input token , Providing contextualized representations . \\n_Masked language model_ :\\nMasking Words : BERT hides about 15% of words in a sentence with a special token . \\nGuessing Hidden words : BERT guesses the masked words by analyzing the context of neighboring words. \\nLearning Process : Uses a special layer to guess and convert these guesses into probabilities . \\n\\n\\nFocus on Masked Words: BERT emphasizes predicting masked words to enhance understanding of context and meaning.\\nNext Sentence Prediction (NSP):\\nSentence Pair Relationship: Trains BERT to understand if two sentences are sequential in a document.\\nBalanced Training Pairs: 50% pairs are consecutive, 50% are random sentences.\\nInput Processing: Add special tokens, sentence embeddings, and positional embeddings to prepare data to do NSP.\\nPrediction Mechanism: Uses the output of CLS token to determine sentence connection and probabilities through a classification layer and SoftMax. \\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split(ed['transcript'][0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from STApp.utils.database import Base, engine\n",
    "\n",
    "# Drop all tables\n",
    "Base.metadata.drop_all(bind=engine)\n",
    "\n",
    "# Recreate tables with the updated schema\n",
    "Base.metadata.create_all(bind=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from STApp.utils.database import create_tables\n",
    "\n",
    "# Recreate the tables\n",
    "create_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {1:'sd',2:f'sds'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_answers(transcript):\n",
    "    # Define a regex pattern to match the start of each answer\n",
    "    # This pattern covers the additional formats like \"Ans.\", \"Ans\", \"Ans1)\", \"Ans)\", \"ans1)\", \"ques 1)\", \"Ques1)\", and \"q1)\"\n",
    "    pattern = r'(?:Answer\\s*\\d+:|Q\\d+:|\\d+\\.\\s|A\\d*\\)|Q\\d*\\)|A\\.|Q\\.|a\\)|A\\s|Q\\s|a\\s|Ans\\.|Ans|Ans\\d*\\)|ans\\d*\\)|ques\\s*\\d*\\)|Ques\\d*\\)|q\\d*\\))'\n",
    "\n",
    "    # Use re.split() to split the transcript by the pattern\n",
    "    answers = re.split(pattern, transcript)\n",
    "\n",
    "    # Remove any empty strings resulting from splitting and strip any leading/trailing whitespace\n",
    "    answers = [answer.strip() for answer in answers if answer.strip()]\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reactive Agents: \\nReactive agents are driven by the principle of responding to changes in their environment. They operate on',\n",
       " 'stimulus-response basis, where they continuously monitor their environment and take actions directly in response to perceived stimuli.\\nEg:',\n",
       " 'robot vacuum cleaner that moves around',\n",
       " 'room, changing direction when it encounters an obstacle. It does not plan its route or remember where it has been, it simply reacts to obstacles in its path. \\nProactive Agents:\\nProactive agents are capable of anticipating future states of the environment and taking actions that move them towards achieving their objectives. \\nEg:',\n",
       " \"chess playing program that anticipates the opponent's moves and plans several steps ahead. \\n\\n\\nto achieve the goal of winning the game. \\na2) Organization as an Agent:\\nThis perspective sees an organization as\",\n",
       " 'unified entity that makes strategic decisions, plans and take actions to achieve specific goals similar to an intelligent agent in',\n",
       " 'multi agent system. For example,',\n",
       " 'multinational corporation acts as',\n",
       " 'single entity in decision-making, negotiations, and competition to maximize profits and achieve long-term objectives.\\nOrganization as an Institutions:\\nThis perspective focuses on the organization as',\n",
       " 'structure composed of rules, norms and roles that guide the behavior of its members. It emphasizes the framework that shapes behaviors within the organization, such as',\n",
       " 'university that operates based on academic rules etc.',\n",
       " 'Accessible Environment: \\nAgents does not have full access to all the information about the state of the environment\\nInaccessible Environment:\\nThese have complete and accurate information about the state of the environment at any given time.\\nDeterministic Environment :\\nIn this environment actions may have uncertain or probabilistic outcomes.\\nNon- deterministic Environment :\\nIn this environment agents actions is predictable and consistent.',\n",
       " 'Belief- desire- Intention :\\nBelief represents the information that an agent has about the world , including its environment , other agents and itself.\\nDesire represents the goals or objectives that the agent wants to achieve. These are the \\n\\n\\noutcomes or states of the world that the agents finds desirable.\\nIntentions are the plans or commitments that an agent decides to pursue in order to achieve it desires. Intentions represent the chosen course of action that the agent is committed to executing.\\nsensor input --> belief revision --> beliefs --> generate options --> desires --> filter --> Intentions --> action output']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separate_answers(resde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    \n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text += page.extract_text()\n",
    "\n",
    "    \n",
    "    qa_dict = {}\n",
    "    \n",
    "    question_pattern = re.compile(r'(Q\\s*\\d+|Ques\\s*\\d+|Question\\s*\\d+):', re.IGNORECASE)\n",
    "    answer_pattern = re.compile(r'(Ans\\s*\\d+|Answer\\s*\\d+|Answ er\\s*\\d+):', re.IGNORECASE)\n",
    "    \n",
    "    questions = re.split(question_pattern, text)\n",
    "    \n",
    "    for i in range(1, len(questions), 2):\n",
    "        question_number = questions[i].strip()\n",
    "        question_text = questions[i + 1].strip()\n",
    "        \n",
    "        answer_match = answer_pattern.search(question_text)\n",
    "        if answer_match:\n",
    "            answer_start = answer_match.start()\n",
    "            answer_number = answer_match.group()\n",
    "            \n",
    "            question_only = question_text[:answer_start].strip().replace('\\n', ' ')\n",
    "            answer_only = question_text[answer_start + len(answer_number):].strip().replace('\\n', ' ')\n",
    "            qa_dict[question_only] = answer_only\n",
    "    \n",
    "    return qa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Explain about proactive and reactive agents.': \"Reactive Agents Reactive agents are driven by the principle of responding to changes in their environment. They operate on a stimulus-response basis, where they continuously monitor their environment and take actions directly in response to perceived stimuli. These agents do not have an internal model of the world or long-term goals; instead, they rely on predefined rules or behaviors that dictate how to respond to specific situations. Example: A classic example of a reactive agent is a robot vacuum cleaner that moves around a room, changing direction when it encounters an obstacle. The vacuum cleaner does not plan its route or remember where it has been; it simply reacts to obstacles in its path. Proactive Agents Proactive agents, in contrast, are driven by internal goals or motivations. These agents are capable of anticipating future states of the environment and taking actions that move them toward achieving their objectives. Proactive agents use planning and reasoning to decide on actions that are not just reactions to immediate stimuli but are aligned with their overall goals. Example: An example of a proactive agent is a chess-playing program that anticipates the opponent's moves and plans several steps ahead to achieve the goal of winning the game. The program doesn't just react to each move; it strategically considers how its actions will affect future states of the game .\",\n",
       " 'Difference between organization as an agent and organization as an institution.': 'Organization as an Agent When viewing an organization as an agent, the organization is conceptualized as a single, coherent entity that acts within an environment to achieve specific goals. This perspective treats the organization much like an intelligent agent in multiagent systems, capable of decision-making, planning, and taking actions. Example: A multinational corporation can be seen as an agent that makes strategic decisions about market entry, product development, and resource allocation to maximize profits and achieve its long-term objectives. The corporation acts as a unified entity in negotiations, legal matters, and competition. Organization as an Institution When considering an organization as an institution, the focus shifts from the organization acting as a single agent to the organization as a structure of rules, norms, and roles that guide the behavior of its members. This perspective emphasizes the organizational framework that shapes the interactions and behaviors of individuals within the organization. Example: A university can be seen as an institution that provides education and research services. It is governed by a set of academic rules, codes of conduct, and cultural traditions that shape the behavior of faculty, staff, and students. The university’s institutional role includes preserving knowledge, fostering critical thinking, and contributing to societal development.',\n",
       " 'Describe any five types of environments in a multi-agent system.': 'Accessible (Fully Observable) Environment: In an accessible environment, agents have complete and accurate information about the state of the environment at any given time. This means that agents can observe all relevant aspects of the environment and use this information to make decisions. Inaccessible (Partially Observable) Environment: In an inaccessible environment, agents do not have full access to all the information about the state of the environment. They may have to make decisions based on incomplete or uncertain data, requiring the use of inference, estimation, or probabilistic reasoning. Deterministic Environment: In a deterministic environment, the outcome of any action taken by an agent is predictable and consistent. Given a specific state and action, the resulting state is always the same. Non-deterministic (Stochastic) Environment: In a non-deterministic environment, actions may have uncertain or probabilistic outcomes. The same action taken in the same state might lead to different results, adding complexity to the decision-making process. Static Environment: A static environment remains unchanged unless an agent interacts with it. The state of the environment does not change over time unless affected by an agent’s actions.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_from_pdf(\"STApp/Images/MAS/MAS_AK.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
